{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3567f716",
   "metadata": {},
   "source": [
    "# Use Snowpark_OpenAI Notebook template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1abde6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting snowflake-connector-python[pandas]',\n",
       " '  Using cached https://files.pythonhosted.org/packages/f8/c7/03d2ca5e460acb3a31d70ee17584fbc6fe828a52c9f83bbb20a392b8988b/snowflake_connector_python-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting idna<4,>=2.5',\n",
       " '  Using cached https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl',\n",
       " 'Collecting pytz',\n",
       " '  Using cached https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl',\n",
       " 'Collecting tomlkit',\n",
       " '  Using cached https://files.pythonhosted.org/packages/07/fa/c96545d741f2fd47f565e4e06bfef0962add790cb9c2289d900102b55eca/tomlkit-0.12.4-py3-none-any.whl',\n",
       " 'Collecting certifi>=2017.4.17',\n",
       " '  Using cached https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl',\n",
       " 'Collecting urllib3<2.0.0,>=1.21.1; python_version < \"3.10\"',\n",
       " '  Using cached https://files.pythonhosted.org/packages/b0/53/aa91e163dcfd1e5b82d8a890ecf13314e3e149c05270cc644581f77f17fd/urllib3-1.26.18-py2.py3-none-any.whl',\n",
       " 'Collecting asn1crypto<2.0.0,>0.24.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/c9/7f/09065fd9e27da0eda08b4d6897f1c13535066174cc023af248fc2a8d5e5a/asn1crypto-1.5.1-py2.py3-none-any.whl',\n",
       " 'Collecting typing-extensions<5,>=4.3',\n",
       " '  Using cached https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl',\n",
       " 'Collecting pyjwt<3.0.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl',\n",
       " 'Collecting cffi<2.0.0,>=1.9',\n",
       " '  Using cached https://files.pythonhosted.org/packages/ea/ac/e9e77bc385729035143e54cc8c4785bd480eaca9df17565963556b0b7a93/cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting packaging',\n",
       " '  Using cached https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl',\n",
       " 'Collecting pyOpenSSL<25.0.0,>=16.2.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/54/a7/2104f674a5a6845b04c8ff01659becc6b8978ca410b82b94287e0b1e018b/pyOpenSSL-24.1.0-py3-none-any.whl',\n",
       " 'Collecting cryptography<43.0.0,>=3.1.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/d4/fa/057f9d7a5364c86ccb6a4bd4e5c58920dcb66532be0cc21da3f9c7617ec3/cryptography-42.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting charset-normalizer<4,>=2',\n",
       " '  Using cached https://files.pythonhosted.org/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting filelock<4,>=3.5',\n",
       " '  Using cached https://files.pythonhosted.org/packages/8b/69/acdf492db27dea7be5c63053230130e0574fd8a376de3555d5f8bbc3d3ad/filelock-3.13.3-py3-none-any.whl',\n",
       " 'Collecting requests<3.0.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl',\n",
       " 'Collecting platformdirs<4.0.0,>=2.6.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/56/29/3ec311dc18804409ecf0d2b09caa976f3ae6215559306b5b530004e11156/platformdirs-3.11.0-py3-none-any.whl',\n",
       " 'Collecting sortedcontainers>=2.4.0',\n",
       " '  Using cached https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl',\n",
       " 'Collecting pandas<3.0.0,>=1.0.0; extra == \"pandas\"',\n",
       " '  Using cached https://files.pythonhosted.org/packages/1a/5e/71bb0eef0dc543f7516d9ddeca9ee8dc98207043784e3f7e6c08b4a6b3d9/pandas-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting pyarrow; extra == \"pandas\"',\n",
       " '  Using cached https://files.pythonhosted.org/packages/c2/9d/b5d4666d78bab32b80275d86043a127d2197431c711a53291b5c94637844/pyarrow-15.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting pycparser',\n",
       " '  Using cached https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl',\n",
       " 'Collecting python-dateutil>=2.8.2',\n",
       " '  Using cached https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl',\n",
       " 'Collecting tzdata>=2022.7',\n",
       " '  Using cached https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl',\n",
       " 'Collecting numpy<2,>=1.22.4; python_version < \"3.11\"',\n",
       " '  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl',\n",
       " 'Collecting six>=1.5',\n",
       " '  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl',\n",
       " \"ERROR: snowflake-ml-python 1.0.10 has requirement packaging<24,>=20.9, but you'll have packaging 24.0 which is incompatible.\",\n",
       " \"ERROR: snowflake-ml-python 1.0.10 has requirement pandas<2,>=1.0.0, but you'll have pandas 2.2.1 which is incompatible.\",\n",
       " \"ERROR: snowflake-ml-python 1.0.10 has requirement scikit-learn<1.4,>=1.2.1, but you'll have scikit-learn 1.4.1.post1 which is incompatible.\",\n",
       " \"ERROR: snowflake-ml-python 1.0.10 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\",\n",
       " \"ERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\",\n",
       " \"ERROR: jupyterlab-server 2.25.3 has requirement jsonschema>=4.18.0, but you'll have jsonschema 3.2.0 which is incompatible.\",\n",
       " 'Installing collected packages: idna, pytz, tomlkit, certifi, urllib3, asn1crypto, typing-extensions, pyjwt, pycparser, cffi, packaging, cryptography, pyOpenSSL, charset-normalizer, filelock, requests, platformdirs, sortedcontainers, six, python-dateutil, tzdata, numpy, pandas, pyarrow, snowflake-connector-python',\n",
       " 'Successfully installed asn1crypto-1.5.1 certifi-2024.2.2 cffi-1.16.0 charset-normalizer-3.3.2 cryptography-42.0.5 filelock-3.13.3 idna-3.6 numpy-1.26.4 packaging-24.0 pandas-2.2.1 platformdirs-3.11.0 pyOpenSSL-24.1.0 pyarrow-15.0.2 pycparser-2.22 pyjwt-2.8.0 python-dateutil-2.9.0.post0 pytz-2024.1 requests-2.31.0 six-1.16.0 snowflake-connector-python-3.7.1 sortedcontainers-2.4.0 tomlkit-0.12.4 typing-extensions-4.11.0 tzdata-2024.1 urllib3-1.26.18',\n",
       " 'WARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/idna-3.6.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/tomlkit-0.12.4.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/urllib3-1.26.18.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/typing_extensions-4.11.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-39-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/packaging-24.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/cryptography-42.0.5.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.1.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/filelock-3.13.3.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/platformdirs-3.11.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pandas-2.2.1.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pyarrow already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/pyarrow-15.0.2.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.7.1.dist-info already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.',\n",
       " 'WARNING: You are using pip version 19.3.1; however, version 24.0 is available.',\n",
       " \"You should consider upgrading via the 'pip install --upgrade pip' command.\"]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install \"snowflake-connector-python[pandas]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71828059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\n",
    "import numpy as np # fundamental package for scientific computing with Python\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c89eec",
   "metadata": {},
   "source": [
    "# Read Customer and Payment data from Snowflake respective tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b0ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all snowflake connection details from template variables.\n",
    "\n",
    "db_user = os.getenv('sf_user')\n",
    "db_password =  'Password@2023' #os.getenv('sf_password')\n",
    "db_account = os.getenv('sf_account')\n",
    "db_database =  os.getenv('sf_db')\n",
    "db_role = os.getenv('sf_role')\n",
    "db_warehouse = 'FOSFOR_FDC'\n",
    "db_schema = 'PUBLIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fd2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "connection_params = {\n",
    "    'user': db_user,\n",
    "    'password': db_password,\n",
    "    'account': db_account,\n",
    "    'warehouse': db_warehouse,\n",
    "    'database': db_database,\n",
    "    'schema': db_schema,\n",
    "    'role': db_role\n",
    "}\n",
    "session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeade4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('use warehouse FOSFOR_FDC;').collect()\n",
    "session.sql('use database FDC_DATA_MANISH;').collect()\n",
    "session.sql('use schema FDC_DATA_MANISH.PUBLIC;').collect()\n",
    "\n",
    "cc_customer = session.table('FDC_DATA_MANISH.PUBLIC.CC_CUSTOMER_DATA').to_pandas()\n",
    "cc_payment = session.table('FDC_DATA_MANISH.PUBLIC.CC_PAYMENT_DATA').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b5eb9",
   "metadata": {},
   "source": [
    "# Reverse Data Engineering to get Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca9bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_customer['FEA_2'] = cc_customer['FEA_2'].replace([0],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d98153",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_payment['PROD_LIMIT'] = cc_payment['PROD_LIMIT'].replace([0],np.nan)\n",
    "cc_payment['HIGHEST_BALANCE'] = cc_payment['HIGHEST_BALANCE'].replace([0],np.nan)\n",
    "\n",
    "cc_payment['UPDATE_DATE'] = cc_payment['UPDATE_DATE'].replace(['31/12/9999'],np.nan)\n",
    "cc_payment['REPORT_DATE'] = cc_payment['REPORT_DATE'].replace(['31/12/9999'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a17bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_customer['FEA_2'] = cc_customer['FEA_2'].replace([np.nan],cc_customer['FEA_2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc2eba65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cc_payment['HIGHEST_BALANCE'] = cc_payment['HIGHEST_BALANCE'].replace([np.nan],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec210844",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_features=['FEA_1', 'FEA_2', 'FEA_3', 'FEA_4', 'FEA_5', 'FEA_6',\n",
    "       'FEA_7', 'FEA_8', 'FEA_9', 'FEA_10', 'FEA_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a1c8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['FEA_3','FEA_5','FEA_6','FEA_9']\n",
    "num_features = ['FEA_1','FEA_2','FEA_4','FEA_7','FEA_8','FEA_10','FEA_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4a033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standerdisation(df,num_cols):\n",
    "# copy of datasets\n",
    "    df_stand = df.copy()\n",
    "\n",
    "    # apply standardization on numerical features\n",
    "    for i in num_cols:\n",
    "\n",
    "        # fit on training data column\n",
    "        scale = StandardScaler().fit(df_stand[[i]])\n",
    "\n",
    "        # transform the training data column\n",
    "        df_stand[i] = scale.transform(df_stand[[i]])\n",
    "        \n",
    "    return df_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2466a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_customer_std =  standerdisation(cc_customer,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2f996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols=[cols for cols  in cc_customer_std.columns if cols not in ['LABEL','ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab75f61",
   "metadata": {},
   "source": [
    "# Preparing data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cc_customer_std[feat_cols]\n",
    "y = cc_customer_std[['LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a8d5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEA_1</th>\n",
       "      <th>FEA_2</th>\n",
       "      <th>FEA_3</th>\n",
       "      <th>FEA_4</th>\n",
       "      <th>FEA_5</th>\n",
       "      <th>FEA_6</th>\n",
       "      <th>FEA_7</th>\n",
       "      <th>FEA_8</th>\n",
       "      <th>FEA_9</th>\n",
       "      <th>FEA_10</th>\n",
       "      <th>FEA_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>1.097352</td>\n",
       "      <td>-1.263992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.552944</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.964028</td>\n",
       "      <td>1.101281</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.087361</td>\n",
       "      <td>0.287234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>-1.072281</td>\n",
       "      <td>0.416866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.971468</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>0.767492</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.607523</td>\n",
       "      <td>0.577444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>-1.072281</td>\n",
       "      <td>-1.357373</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.824419</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>-0.901452</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.607516</td>\n",
       "      <td>0.462693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.097352</td>\n",
       "      <td>-0.952722</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.620813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>-1.819371</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.872046</td>\n",
       "      <td>0.706044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.097352</td>\n",
       "      <td>0.759263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.021306</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>-0.400769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.685954</td>\n",
       "      <td>0.685220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FEA_1     FEA_2  FEA_3     FEA_4  FEA_5  FEA_6     FEA_7     FEA_8  \\\n",
       "802  1.097352 -1.263992    3.0 -0.552944    2.0   11.0 -1.964028  1.101281   \n",
       "567 -1.072281  0.416866    3.0 -0.971468    2.0    8.0  0.056269  0.767492   \n",
       "574 -1.072281 -1.357373    3.0 -0.824419    2.0    8.0  0.056269 -0.901452   \n",
       "411  1.097352 -0.952722    3.0 -0.620813    2.0   11.0  0.056269 -1.819371   \n",
       "70   1.097352  0.759263    1.0 -0.021306    2.0   11.0  0.056269 -0.400769   \n",
       "\n",
       "     FEA_9    FEA_10    FEA_11  \n",
       "802    5.0 -0.087361  0.287234  \n",
       "567    4.0 -0.607523  0.577444  \n",
       "574    5.0 -0.607516  0.462693  \n",
       "411    3.0  1.872046  0.706044  \n",
       "70     3.0 -0.685954  0.685220  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21878c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LABEL\n",
       "802    0.0\n",
       "567    1.0\n",
       "574    1.0\n",
       "411    0.0\n",
       "70     0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd962461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train features :- (956, 11)\n",
      "Shape of Test features  :- (169, 11)\n",
      "Shape of Train Target   :- (956, 1)\n",
      "Shape of Test Target    :- (169, 1)\n"
     ]
    }
   ],
   "source": [
    "X.reset_index(inplace=True)\n",
    "y.reset_index(inplace=True)\n",
    "\n",
    "X.drop(columns=['index'],axis=1,inplace=True)\n",
    "y.drop(columns=['index'],axis=1,inplace=True)\n",
    "\n",
    "print('Shape of Train features :-',X.shape)\n",
    "print('Shape of Train Target   :-',y.shape)\n",
    "y = y['LABEL'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfa83a",
   "metadata": {},
   "source": [
    "# Registaring the finalized Model using SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "efe9090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting refractml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/0d/023d845cf453feb632b08435c91f7e5d050c0df73c5be66bdbbca2f6ba87/refractml-1.0.3-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3==1.26.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl (140kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 17.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-toolbelt==0.9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 23.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Collecting PyYAML==6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/fc/a4d5a7554e0067677823f7265cb3ae22aed8a238560b5133b58cda252dad/PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 85.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mosaic-utils\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/d7/8424b1dcaa5b1a2f824fc440aa1c4ef45e0bf6593d11b37962311614f365/mosaic_utils-1.0.2-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 18.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shutils==0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/46/1d/8c6017828045c2d510e2d1d480b563936be7755c97cff660afed947928b6/shutils-0.1.0.tar.gz\n",
      "Collecting requests<3.0.0,>=2.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting scikit-learn==1.2.1; python_version >= \"3.8\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/5b/a3ee68c28dde18b9b744124c7e1701b8e5d588c8b0ef44d233864a97cffc/scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6MB 83.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting configparser\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/c1/c9d33f208bf25164ec315a571a9c0a6b71a5d38f364426db987cec12a152/configparser-6.0.1-py3-none-any.whl\n",
      "Collecting pymysql\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 17.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/ba/a778e6c0020d728c119b0379805a357135fe8c9bc87fdb7e0750ca11319f/scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/1e/84/ccd9b08653022b7785b6e3ee070ffb2825841e0dc119be22f0840b2b35cb/threadpoolctl-3.4.0-py3-none-any.whl\n",
      "Building wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-cp39-none-any.whl size=3274 sha256=cfd251dfe8be4e6cac1fbf2cae7cecddcf2bb7397bbb94a46d5b088e9db84299\n",
      "  Stored in directory: /home/mosaic-ai/.cache/pip/wheels/ab/d0/0e/613976a1b51b5654859e2a82ade64329859bce431e280f2a39\n",
      "Successfully built shutils\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement cloudpickle>=2.0.0, but you'll have cloudpickle 1.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement packaging<24,>=20.9, but you'll have packaging 24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement pandas<2,>=1.0.0, but you'll have pandas 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: snowflake-ml-python 1.0.10 has requirement xgboost<2,>=1.7.3, but you'll have xgboost 2.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.25.3 has requirement jsonschema>=4.18.0, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests, requests-toolbelt, cloudpickle, PyYAML, joblib, numpy, scipy, threadpoolctl, scikit-learn, mosaic-utils, configparser, pymysql, shutils, refractml\n",
      "Successfully installed PyYAML-6.0 certifi-2024.2.2 charset-normalizer-3.3.2 cloudpickle-1.6.0 configparser-6.0.1 idna-3.6 joblib-1.3.2 mosaic-utils-1.0.2 numpy-1.26.4 pymysql-1.1.0 refractml-1.0.3 requests-2.31.0 requests-toolbelt-0.9.1 scikit-learn-1.2.1 scipy-1.13.0 shutils-0.1.0 threadpoolctl-3.4.0 urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.0 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install refractml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "23beb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8683d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    import json\n",
    "    payload = request.json[\"payload\"]\n",
    "    if isinstance(request.json[\"payload\"],str):\n",
    "        payload_data = eval(payload)\n",
    "        data = pd.DataFrame(payload_data)\n",
    "        prediction = model.predict(data)\n",
    "        return prediction.tolist()\n",
    "    return \"This method is not allowed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a5472642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0973519472438964,\n",
       " 0.5413737175808717,\n",
       " 1.0,\n",
       " 0.2162349125628913,\n",
       " 2.0,\n",
       " 11.0,\n",
       " 0.05626900238247806,\n",
       " -0.9014522862446314,\n",
       " 5.0,\n",
       " -0.6862227070682823,\n",
       " 0.5774440911347185]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX_test.iloc[1].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "81cdc453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'payload': \"{'FEA_1': {0: -1.0722806373771643}, 'FEA_2': {0: -0.6414521108514917}, 'FEA_3': {0: 3.0}, 'FEA_4': {0: -0.41720689397770927}, 'FEA_5': {0: 2.0}, 'FEA_6': {0: 8.0}, 'FEA_7': {0: 0.05626900238247806}, 'FEA_8': {0: 0.5171501143501661}, 'FEA_9': {0: 4.0}, 'FEA_10': {0: -0.6075163209160109}, 'FEA_11': {0: 0.3394082336702392}}\"}\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "# one row as input\n",
    "payload = str(newX_test.iloc[:1].to_dict())\n",
    "req = requests.Request()\n",
    "req.json= {'payload': payload}\n",
    "print({'payload': payload})\n",
    "print(score(randmf, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "54c3d60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'payload': \"{'FEA_1': {0: -1.0722806373771643, 1: 1.0973519472438964}, 'FEA_2': {0: -0.6414521108514917, 1: 0.5413737175808717}, 'FEA_3': {0: 3.0, 1: 1.0}, 'FEA_4': {0: -0.41720689397770927, 1: 0.2162349125628913}, 'FEA_5': {0: 2.0, 1: 2.0}, 'FEA_6': {0: 8.0, 1: 11.0}, 'FEA_7': {0: 0.05626900238247806, 1: 0.05626900238247806}, 'FEA_8': {0: 0.5171501143501661, 1: -0.9014522862446314}, 'FEA_9': {0: 4.0, 1: 5.0}, 'FEA_10': {0: -0.6075163209160109, 1: -0.6862227070682823}, 'FEA_11': {0: 0.3394082336702392, 1: 0.5774440911347185}}\"}\n",
      "[1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Two rows as input\n",
    "payload = str(newX_test.iloc[:2].to_dict())\n",
    "req = requests.Request()\n",
    "req.json= {'payload': payload}\n",
    "print({'payload': payload})\n",
    "print(score(randmf, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5a52a9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating build time metrics\n",
      "\n",
      "Progress: ██████████████████████████████████████████████████████████████████████ 100.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5881f36735bd480581419ae67725f0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(randmf, \n",
    "               score, \n",
    "               name=\"Credit_Risk_Model\", \n",
    "               description=\"Credit_Risk_Model_RandomForest\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               y_true=newy_test,\n",
    "               y_pred=newy_pred_rf, \n",
    "               features=newX_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               prob=newy_pred_rf,\n",
    "               x_train=newX_train, \n",
    "               x_test=newX_test, \n",
    "               y_train=newy_train['LABEL'].tolist(),\n",
    "               y_test=newy_test['LABEL'].tolist(),\n",
    "               feature_names=newX_train.columns.tolist(),\n",
    "               original_features=newX_train.columns.tolist(),\n",
    "               feature_ids=newX_train.columns,\n",
    "               kyd=True,\n",
    "               kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "574036e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'FEA_1': {0: -1.0722806373771643, 1: 1.0973519472438964}, 'FEA_2': {0: -0.6414521108514917, 1: 0.5413737175808717}, 'FEA_3': {0: 3.0, 1: 1.0}, 'FEA_4': {0: -0.41720689397770927, 1: 0.2162349125628913}, 'FEA_5': {0: 2.0, 1: 2.0}, 'FEA_6': {0: 8.0, 1: 11.0}, 'FEA_7': {0: 0.05626900238247806, 1: 0.05626900238247806}, 'FEA_8': {0: 0.5171501143501661, 1: -0.9014522862446314}, 'FEA_9': {0: 4.0, 1: 5.0}, 'FEA_10': {0: -0.6075163209160109, 1: -0.6862227070682823}, 'FEA_11': {0: 0.3394082336702392, 1: 0.5774440911347185}}\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Payload for future reference\n",
    "payload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
